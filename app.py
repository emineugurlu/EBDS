# app.py - Streamlit UygulamasÄ±

import streamlit as st
from nlp_model import get_embedding
from web_scraper import search_and_scrape
from knowledge_base import KNOWLEDGE_BASE
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pickle
import os
import re

EMBEDDINGS_FILE = "embeddings.pkl"

@st.cache_resource # Modeli ve embedding'leri bir kez yÃ¼klemek iÃ§in
def load_resources():
    """NLP modelini ve bilgi bankasÄ± embedding'lerini yÃ¼kler veya oluÅŸturur."""
    # NLP modeli nlp_model.py iÃ§inde zaten tek seferlik yÃ¼klendiÄŸi iÃ§in
    # burada tekrar bir yÃ¼kleme fonksiyonu Ã§aÄŸÄ±rmaya gerek yok,
    # get_embedding Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda zaten yÃ¼klÃ¼ olacaktÄ±r.

    if os.path.exists(EMBEDDINGS_FILE):
        st.write(f"'{EMBEDDINGS_FILE}' dosyasÄ±ndan bilgi bankasÄ± embedding'leri yÃ¼kleniyor...")
        with open(EMBEDDINGS_FILE, 'rb') as f:
            return pickle.load(f)
    else:
        st.write("Bilgi bankasÄ± embedding'leri oluÅŸturuluyor...")
        embeddings = {
            anahtar: get_embedding(anahtar) for anahtar in KNOWLEDGE_BASE.keys()
        }
        with open(EMBEDDINGS_FILE, 'wb') as f:
            pickle.dump(embeddings, f)
        st.write(f"Bilgi bankasÄ± embedding'leri '{EMBEDDINGS_FILE}' dosyasÄ±na kaydedildi.")
        return embeddings

# KaynaklarÄ± yÃ¼kle (Streamlit uygulamasÄ±nÄ±n baÅŸÄ±nda bir kez Ã§alÄ±ÅŸÄ±r)
bilgi_bankasi_embeddings = load_resources()

def preprocess_query(query):
    """KullanÄ±cÄ± sorgusunu temizler ve kÃ¼Ã§Ã¼k harfe dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    query = query.lower().strip()
    query = re.sub(r'[^\w\s]', '', query)
    query = re.sub(r'\s+', ' ', query).strip()
    return query

def temel_bilim_asistani(soru):
    """
    NLP entegrasyonu ve Web Scraping ile daha akÄ±llÄ± bir temel bilim asistanÄ±.
    Streamlit uygulamasÄ± iÃ§in uyarlanmÄ±ÅŸtÄ±r.
    """
    # "Ã§Ä±kÄ±ÅŸ" komutu Streamlit arayÃ¼zÃ¼nde doÄŸrudan kontrol edilmeyecek,
    # uygulama kapatÄ±ldÄ±ÄŸÄ±nda veya tarayÄ±cÄ± sekmesi kapatÄ±ldÄ±ÄŸÄ±nda durur.

    islenmis_soru = preprocess_query(soru) # Bilgi bankasÄ± eÅŸleÅŸmesi iÃ§in iÅŸlenmiÅŸ sorgu
    soru_embedding = get_embedding(islenmis_soru)

    en_yuksek_benzerlik = -1
    en_benzer_anahtar = None

    for anahtar, embedding in bilgi_bankasi_embeddings.items():
        benzerlik = cosine_similarity(soru_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]
        if benzerlik > en_yuksek_benzerlik:
            en_yuksek_benzerlik = benzerlik
            en_benzer_anahtar = anahtar

    if en_yuksek_benzerlik > 0.65: # EÅŸik deÄŸeri
        return f"EBDS AsistanÄ±: {KNOWLEDGE_BASE[en_benzer_anahtar]}"
    else:
        st.write("Bilgi bankasÄ±nda bulunamadÄ±. Web'de aranÄ±yor...")
        web_sonuc = search_and_scrape(soru)

        if web_sonuc and not ("Web'den Ã§ekilen metin anlamlÄ± deÄŸil veya Ã§ok kÄ±sa." in web_sonuc or \
                              "DuckDuckGo aramasÄ±nda uygun bir baÄŸlantÄ± bulunamadÄ±." in web_sonuc or \
                              "Web isteÄŸi hatasÄ±" in web_sonuc or \
                              "Web sayfasÄ±nÄ± iÅŸlerken bir sorun oluÅŸtu" in web_sonuc):
            return f"EBDS AsistanÄ± (Web'den): {web_sonuc}"
        else:
            return f"EBDS AsistanÄ±: ÃœzgÃ¼nÃ¼m, bu konu hakkÄ±nda henÃ¼z bilgiye sahip deÄŸilim veya yeterince ilgili bir bilgi bulamadÄ±m. ({web_sonuc})"


# --- Streamlit ArayÃ¼zÃ¼ ---
st.set_page_config(page_title="EBDS Temel Bilim AsistanÄ±", page_icon=":brain:")

st.title("ğŸ”¬ EBDS Temel Bilim AsistanÄ±")
st.markdown("Temel bilimler alanÄ±ndaki sorularÄ±nÄ±za yanÄ±t bulmak iÃ§in buradayÄ±m!")

# KullanÄ±cÄ±dan soru alma
kullanici_sorusu = st.text_input("Sorunuzu buraya yazÄ±n:", key="user_input")

if kullanici_sorusu:
    with st.spinner("YanÄ±t aranÄ±yor..."): # KullanÄ±cÄ±ya arama yapÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶ster
        cevap = temel_bilim_asistani(kullanici_sorusu)
        st.info(cevap) # YanÄ±tÄ± bilgi kutusunda gÃ¶ster

st.markdown("---")
st.markdown("Bu asistan, 'insanlÄ±k iÃ§in bÃ¼yÃ¼k bir proje' vizyonuyla geliÅŸtirilmiÅŸtir.")